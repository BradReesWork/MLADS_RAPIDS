{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.41\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: - ^C\n",
      "| "
     ]
    }
   ],
   "source": [
    "!conda install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script sh --out /dev/null --err /dev/null\n",
    "cd .. && mkdir -p data/mortgage_2000 && cd data/mortgage_2000 && wget http://rapidsai-data.s3-website.us-east-2.amazonaws.com/notebook-mortgage-data/mortgage_2000.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names.csv\n",
      "acq/Acquisition_2000Q4.txt\n",
      "acq/Acquisition_2000Q3.txt\n",
      "acq/Acquisition_2000Q2.txt\n",
      "acq/Acquisition_2000Q1.txt\n",
      "perf/Performance_2000Q4.txt\n",
      "perf/Performance_2000Q3.txt\n",
      "perf/Performance_2000Q2.txt\n",
      "perf/Performance_2000Q1.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "cd ../data/mortgage_2000 && tar -xvf mortgage_2000.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.environ.get(\"SUBSCRIPTION_ID\", \"\")\n",
    "resource_group = os.environ.get(\"RESOURCE_GROUP\", \"\")\n",
    "workspace_name = os.environ.get(\"WORKSPACE_NAME\", \"\")\n",
    "# workspace_region = os.environ.get(\"WORKSPACE_REGION\", \"\")\n",
    "\n",
    "ws = Workspace(workspace_name=workspace_name, subscription_id=subscription_id, resource_group=resource_group)\n",
    "\n",
    "# write config to a local directory for future use\n",
    "# ws.write_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './1_pandasVsRapids_ETL.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6581f1d0f153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./1_pandasVsRapids_ETL.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscripts_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1_pandasVsRapids_ETL.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscripts_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./1_pandasVsRapids_ETL.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess_data_script\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/conda/envs/rapids/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './1_pandasVsRapids_ETL.py'"
     ]
    }
   ],
   "source": [
    "scripts_folder = \"scripts\"\n",
    "\n",
    "# import shutil\n",
    "# shutil.copy('./1_pandasVsRapids_ETL.py', os.path.join(scripts_folder, '1_pandasVsRapids_ETL.py'))\n",
    "\n",
    "# with open(os.path.join(scripts_folder, './1_pandasVsRapids_ETL.py'), 'r') as process_data_script:\n",
    "#     print(process_data_script.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new cluster\n",
      "Creating\n",
      "Succeeded........................\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "gpu_cluster_name = \"gpu-todrabas\"\n",
    "\n",
    "if gpu_cluster_name in ws.compute_targets:\n",
    "    gpu_cluster = ws.compute_targets[gpu_cluster_name]\n",
    "    \n",
    "    if gpu_cluster and type(gpu_cluster) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + gpu_cluster_name)\n",
    "else:\n",
    "    print(\"creating new cluster\")\n",
    "    # vm_size parameter below could be modified to one of the RAPIDS-supported VM types\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_NC6s_v2\", min_nodes=1, max_nodes = 1)\n",
    "\n",
    "    # create the cluster\n",
    "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\n",
    "    gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import hashlib\n",
    "from urllib.request import urlretrieve\n",
    "# from progressbar import ProgressBar\n",
    "\n",
    "def validate_downloaded_data(path):\n",
    "    if(os.path.isdir(path) and os.path.exists(path + '//names.csv')) :\n",
    "        if(os.path.isdir(path + '//acq' ) and len(os.listdir(path + '//acq')) == 8):\n",
    "            if(os.path.isdir(path + '//perf' ) and len(os.listdir(path + '//perf')) == 11):\n",
    "                print(\"Data has been downloaded and decompressed at: {0}\".format(path))\n",
    "                return True\n",
    "    print(\"Data has not been downloaded and decompressed\")\n",
    "    return False\n",
    "\n",
    "# def show_progress(count, block_size, total_size):\n",
    "#     global pbar\n",
    "#     global processed\n",
    "    \n",
    "#     if count == 0:\n",
    "#         pbar = ProgressBar(maxval=total_size)\n",
    "#         processed = 0\n",
    "    \n",
    "#     processed += block_size\n",
    "#     processed = min(processed,total_size)\n",
    "#     pbar.update(processed)\n",
    "\n",
    "        \n",
    "def download_file(fileroot):\n",
    "    filename = fileroot + '.tgz'\n",
    "    if(not os.path.exists(filename) or hashlib.md5(open(filename, 'rb').read()).hexdigest() != '82dd47135053303e9526c2d5c43befd5' ):\n",
    "        url_format = 'http://rapidsai-data.s3-website.us-east-2.amazonaws.com/notebook-mortgage-data/{0}.tgz'\n",
    "        url = url_format.format(fileroot)\n",
    "        print(\"...Downloading file :{0}\".format(filename))\n",
    "        urlretrieve(url, filename)\n",
    "#         pbar.finish()\n",
    "        print(\"...File :{0} finished downloading\".format(filename))\n",
    "    else:\n",
    "        print(\"...File :{0} has been downloaded already\".format(filename))\n",
    "    return filename\n",
    "\n",
    "def decompress_file(filename,path):\n",
    "    tar = tarfile.open(filename)\n",
    "    print(\"...Getting information from {0} about files to decompress\".format(filename))\n",
    "    members = tar.getmembers()\n",
    "    numFiles = len(members)\n",
    "    so_far = 0\n",
    "    for member_info in members:\n",
    "        tar.extract(member_info,path=path)\n",
    "#         show_progress(so_far, 1, numFiles)\n",
    "        so_far += 1\n",
    "#     pbar.finish()\n",
    "    print(\"...All {0} files have been decompressed\".format(numFiles))\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has not been downloaded and decompressed\n",
      "Downloading and Decompressing Input Data\n",
      "...Downloading file :mortgage_2000.tgz\n",
      "...File :mortgage_2000.tgz finished downloading\n",
      "...Getting information from mortgage_2000.tgz about files to decompress\n",
      "...All 9 files have been decompressed\n",
      "Input Data has been Downloaded and Decompressed\n"
     ]
    }
   ],
   "source": [
    "fileroot = 'mortgage_2000'\n",
    "path = '.\\\\{0}'.format(fileroot)\n",
    "pbar = None\n",
    "processed = 0\n",
    "\n",
    "if(not validate_downloaded_data(path)):\n",
    "    print(\"Downloading and Decompressing Input Data\")\n",
    "    filename = download_file(fileroot)\n",
    "    decompress_file(filename,path)\n",
    "    print(\"Input Data has been Downloaded and Decompressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading .\\mortgage_2000/acq/Acquisition_2000Q1.txt\n",
      "Uploading .\\mortgage_2000/acq/Acquisition_2000Q2.txt\n",
      "Uploading .\\mortgage_2000/acq/Acquisition_2000Q3.txt\n",
      "Uploading .\\mortgage_2000/acq/Acquisition_2000Q4.txt\n",
      "Uploading .\\mortgage_2000/names.csv\n",
      "Uploading .\\mortgage_2000/perf/Performance_2000Q1.txt\n",
      "Uploading .\\mortgage_2000/perf/Performance_2000Q2.txt\n",
      "Uploading .\\mortgage_2000/perf/Performance_2000Q3.txt\n",
      "Uploading .\\mortgage_2000/perf/Performance_2000Q4.txt\n",
      "Uploaded .\\mortgage_2000/names.csv, 1 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/acq/Acquisition_2000Q1.txt, 2 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/acq/Acquisition_2000Q2.txt, 3 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/acq/Acquisition_2000Q4.txt, 4 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/acq/Acquisition_2000Q3.txt, 5 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/perf/Performance_2000Q2.txt, 6 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/perf/Performance_2000Q3.txt, 7 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/perf/Performance_2000Q4.txt, 8 files out of an estimated total of 9\n",
      "Uploaded .\\mortgage_2000/perf/Performance_2000Q1.txt, 9 files out of an estimated total of 9\n"
     ]
    }
   ],
   "source": [
    "# fileroot = 'data\\mortagage_2000'\n",
    "# path = '.\\\\{0}'.format(fileroot)\n",
    "# print(path)\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "# download and uncompress data in a local directory before uploading to data store\n",
    "# directory specified in src_dir parameter below should have the acq, perf directories with data and names.csv file\n",
    "ds.upload(src_dir=path, target_path=fileroot, overwrite=True, show_progress=True)\n",
    "\n",
    "# data already uploaded to the datastore\n",
    "data_ref = DataReference(data_reference_name='data', datastore=ds, path_on_datastore=fileroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 31 18:24:56 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0  On |                  N/A |\n",
      "| 31%   46C    P8    29W / 250W |   2996MiB / 12034MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN V             Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 28%   38C    P8    N/A /  N/A |     12MiB / 12036MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfiguration()\n",
    "run_config.framework = 'python'\n",
    "run_config.environment.python.user_managed_dependencies = True\n",
    "run_config.environment.python.interpreter_path = '/conda/envs/rapids/bin/python'\n",
    "run_config.target = gpu_cluster_name\n",
    "run_config.environment.docker.enabled = True\n",
    "run_config.environment.docker.gpu_support = True\n",
    "run_config.environment.docker.base_image = \"rapidsai/rapidsai:cuda9.2-runtime-ubuntu18.04\"\n",
    "# run_config.environment.docker.base_image_registry.address = '<registry_url>' # not required if the base_image is in Docker hub\n",
    "# run_config.environment.docker.base_image_registry.username = '<user_name>' # needed only for private images\n",
    "# run_config.environment.docker.base_image_registry.password = '<password>' # needed only for private images\n",
    "run_config.environment.spark.precache_packages = False\n",
    "run_config.data_references={'data':data_ref.to_config()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: rapidstest_cpu_1559329102_76a4e0f3\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/MLADS_todrabas/providers/Microsoft.MachineLearningServices/workspaces/todrabas_MLADS_WE/experiments/rapidstest_cpu/runs/rapidstest_cpu_1559329102_76a4e0f3\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Warning: Couldn't instantiate AppInsights telemetry client. Telemetry disabled.\n",
      "Warning: Unable to import azureml.history. Output collection disabled.\n",
      "Running ETL...\n",
      "/mnt/batch/tasks/shared/LS_root/jobs/todrabas_mlads_we/azureml/rapidstest_cpu_1559329102_76a4e0f3/mounts/workspaceblobstore/mortgage_2000/acq/Acquisition_2000Q1.txt\n",
      "/mnt/batch/tasks/shared/LS_root/jobs/todrabas_mlads_we/azureml/rapidstest_cpu_1559329102_76a4e0f3/mounts/workspaceblobstore/mortgage_2000/perf/Performance_2000Q1.txt\n"
     ]
    }
   ],
   "source": [
    "src = ScriptRunConfig(source_directory=scripts_folder, \n",
    "                          script='1_pandasVsRapids_ETL.py', \n",
    "                          arguments = ['--gpu', 0, '--data_dir', str(data_ref)\n",
    "                                      ],\n",
    "                          run_config=run_config\n",
    "                         )\n",
    "\n",
    "exp = Experiment(ws, 'rapidstest_cpu')\n",
    "run = exp.submit(config=src)\n",
    "# RunDetails(run).show()\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# delete the cluster\n",
    "# gpu_cluster.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
